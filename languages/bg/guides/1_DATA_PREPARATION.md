# Ръководство 1: Подготовка на данни за TTS обучение

**Навигация:** [Главно README]({{ site.baseurl }}/languages/bg/){: .btn .btn-primary} | [Следваща стъпка: Настройка за обучение](./2_TRAINING_SETUP.md){: .btn .btn-primary} | 

Това ръководство обхваща критичната първа фаза на всеки TTS проект: подготовка на висококачествени, правилно форматирани аудио и текстови данни. Качеството на вашия набор от данни директно влияе върху качеството на крайния TTS модел.

---

## 1. Стъпки за подготовка на набора от данни

Следвайте тези стъпки систематично, за да трансформирате суровото аудио в набор от данни, готов за обучение.

### 1.1. Придобиване на аудио и първоначална обработка

-   **Събиране на аудио:** Съберете вашите сурови аудио файлове (често срещаните формати включват WAV, MP3, FLAC, OGG, M4A). Уверете се, че имате правата да използвате това аудио.
-   **Конвертиране в WAV:** Повечето TTS рамки очакват WAV формат. Използвайте инструменти като `ffmpeg` или аудио библиотеки (`pydub`, `soundfile`), за да конвертирате вашето аудио. Целете се към стандартно WAV кодиране като PCM 16-bit.
    ```bash
    # Пример с използване на ffmpeg за конвертиране на MP3 в WAV
    ffmpeg -i входно_аудио.mp3 изходно_аудио.wav
    ```
-   **Стандартизиране на каналите (Моно):** TTS моделите обикновено се обучават на едноканално (моно) аудио. Конвертирайте стерео записите в моно.
    ```bash
    # Пример с използване на ffmpeg за конвертиране на стерео WAV в моно WAV
    ffmpeg -i стерео_вход.wav -ac 1 моно_изход.wav
    ```
    *   `-ac 1`: Задава броя на аудио каналите на 1.
-   **Ресемплиране на аудио:** Уверете се, че всички аудио файлове имат **точно същата честота на семплиране**. Изберете целевата честота въз основа на целите на вашия проект и съвместимостта с рамката (напр. 16000 Hz, 22050 Hz, 48000 Hz). 22050 Hz е често срещана за много модели.
    ```bash
    # Пример с използване на ffmpeg за ресемплиране до 22050 Hz
    ffmpeg -i вход.wav -ar 22050 ресемплиран_изход.wav
    ```
    *   `-ar 22050`: Задава честотата на семплиране на 22050 Hz.

### 1.2. Сегментиране на аудио

-   **Разделяне на дълги записи:** Разделете дълги аудио файлове на по-малки сегменти (обикновено 1-15 секунди). Това е критично за ефективно обучение.
    -   Използвайте инструменти като `pydub`, `librosa` или `ffmpeg` за автоматично сегментиране.
    -   Сегментирайте при естествени паузи, когато е възможно.
    -   Избягвайте прекалено кратки (<1 секунда) или прекалено дълги (>15 секунди) сегменти.

```python
# Пример за Python скрипт за сегментиране на аудио при тишина
from pydub import AudioSegment
from pydub.silence import split_on_silence

звук = AudioSegment.from_wav("дълъг_запис.wav")
сегменти = split_on_silence(
    звук, 
    # Определете тишината като звук с интензитет под -40 dBFS
    min_silence_len=500,  # Минимална дължина на тишината в ms
    silence_thresh=-40,   # Праг за тишина в dBFS
    keep_silence=400      # Запазете малко тишина в началото и края
)

# Запазете всеки сегмент като отделен файл
for i, сегмент in enumerate(сегменти):
    сегмент.export(f"сегмент_{i}.wav", format="wav")
```

### 1.3. Почистване на аудио

-   **Премахване на шума:** Използвайте инструменти като SoX, Audacity или специализирани библиотеки за премахване на фонов шум.
    ```bash
    # Пример с използване на SoX за премахване на шума
    # Първо, създайте профил на шума от тих сегмент
    sox тих_сегмент.wav -n noiseprof шумов_профил
    # След това приложете филтъра за намаляване на шума
    sox шумен_вход.wav почистен_изход.wav noisered шумов_профил 0.21
    ```
-   **Нормализиране на силата на звука:** Стандартизирайте нивата на силата на звука във всички файлове.
    ```bash
    # Пример с използване на ffmpeg за нормализиране на силата на звука
    ffmpeg -i вход.wav -filter:a loudnorm нормализиран_изход.wav
    ```
-   **Изрязване на тишината:** Премахнете излишната тишина в началото и края на файловете.
    ```bash
    # Пример с използване на ffmpeg за изрязване на тишината
    ffmpeg -i вход.wav -af silenceremove=start_periods=1:start_duration=0.1:start_threshold=-60dB:detection=peak,aformat=dblp,areverse,silenceremove=start_periods=1:start_duration=0.1:start_threshold=-60dB:detection=peak,aformat=dblp,areverse изрязан_изход.wav
    ```

### 1.4. Транскрибиране на аудио

-   **Създаване на транскрипции:** За всеки аудио сегмент, създайте точна текстова транскрипция.
    -   **Ръчно транскрибиране:** Най-точният метод, но отнема време.
    -   **Автоматично транскрибиране:** Използвайте ASR (Automatic Speech Recognition) системи като Whisper, Vosk или Google Speech-to-Text, последвано от ръчна проверка.
    ```python
    # Пример с използване на OpenAI Whisper за транскрибиране
    import whisper

    модел = whisper.load_model("base")  # Изберете размер на модела: tiny, base, small, medium, large
    резултат = модел.transcribe("аудио_сегмент.wav")
    транскрипция = резултат["text"]
    
    # Запазете транскрипцията във файл
    with open("аудио_сегмент.txt", "w", encoding="utf-8") as f:
        f.write(транскрипция)
    ```
-   **Почистване на текста:** Стандартизирайте текста за последователност.
    -   Премахнете излишни интерпункционни знаци или форматиране.
    -   Стандартизирайте числа, съкращения и специални символи.
    -   Уверете се, че текстът съответства точно на говореното аудио.

### 1.5. Организиране на набора от данни

-   **Структура на директорията:** Създайте ясна структура на директорията за вашия набор от данни.
    ```
    dataset/
    ├── wavs/                   # Директория с всички аудио файлове
    │   ├── segment_0001.wav
    │   ├── segment_0002.wav
    │   └── ...
    ├── metadata.csv            # Файл с метаданни, свързващ аудио с текст
    └── (допълнителни файлове, специфични за рамката)
    ```
-   **Създаване на файл с метаданни:** Повечето TTS рамки изискват CSV или JSON файл, свързващ аудио файловете с техните транскрипции.
    ```
    # Пример за формат на metadata.csv
    # Формат: <име_на_файл>|<говорител_id>|<текст>
    segment_0001.wav|speaker1|Това е пример за транскрибиран текст.
    segment_0002.wav|speaker1|Друг пример за транскрибиран текст.
    ```

### 1.6. Проверка на качеството на данните

-   **Проверка на аудио файловете:** Уверете се, че всички аудио файлове имат правилния формат, честота на семплиране и канали.
    ```bash
    # Пример с използване на ffprobe за проверка на аудио файл
    ffprobe -v error -show_entries stream=sample_rate,channels,codec_name -of default=noprint_wrappers=1 аудио_файл.wav
    ```
-   **Проверка на транскрипциите:** Уверете се, че всички транскрипции са точни и съответстват на аудиото.
-   **Проверка на целостта на набора от данни:** Уверете се, че всеки аудио файл има съответна транскрипция и обратно.

```python
# Пример за Python скрипт за проверка на целостта на набора от данни
import os
import pandas as pd

# Зареждане на метаданните
метаданни = pd.read_csv("metadata.csv", sep="|", header=None, 
                      names=["файл", "говорител", "текст"])

# Проверка дали всички аудио файлове съществуват
директория_с_аудио = "wavs/"
липсващи_файлове = []

for файл in метаданни["файл"]:
    пълен_път = os.path.join(директория_с_аудио, файл)
    if not os.path.exists(пълен_път):
        липсващи_файлове.append(файл)

if липсващи_файлове:
    print(f"Липсват {len(липсващи_файлове)} аудио файла!")
    print(липсващи_файлове[:5])  # Показване на първите 5 липсващи файла
else:
    print("Всички аудио файлове съществуват!")

# Проверка за празни транскрипции
празни_транскрипции = метаданни[метаданни["текст"].isna() | (метаданни["текст"] == "")]
if not празни_транскрипции.empty:
    print(f"Намерени {len(празни_транскрипции)} празни транскрипции!")
else:
    print("Няма празни транскрипции!")
```

### 1.7. Разделяне на набора от данни

-   **Разделяне на обучение/валидация/тест:** Разделете вашия набор от данни на подмножества за обучение (обикновено 80-90%), валидация (5-10%) и тест (5-10%).
    -   Обучение: Използва се за обучение на модела.
    -   Валидация: Използва се за настройка на хиперпараметрите и мониторинг на обучението.
    -   Тест: Използва се за окончателна оценка на модела.

```python
# Пример за Python скрипт за разделяне на набора от данни
import pandas as pd
from sklearn.model_selection import train_test_split

# Зареждане на метаданните
метаданни = pd.read_csv("metadata.csv", sep="|", header=None, 
                      names=["файл", "говорител", "текст"])

# Първо разделяне: 90% обучение+валидация, 10% тест
обуч_вал, тест = train_test_split(метаданни, test_size=0.1, random_state=42)

# Второ разделяне: 90% обучение, 10% валидация от обуч_вал (което е 9% от общото)
обучение, валидация = train_test_split(обуч_вал, test_size=0.1, random_state=42)

# Запазване на разделените метаданни
обучение.to_csv("metadata_train.csv", sep="|", header=False, index=False)
валидация.to_csv("metadata_val.csv", sep="|", header=False, index=False)
тест.to_csv("metadata_test.csv", sep="|", header=False, index=False)

print(f"Общо записи: {len(метаданни)}")
print(f"Записи за обучение: {len(обучение)} ({len(обучение)/len(метаданни)*100:.1f}%)")
print(f"Записи за валидация: {len(валидация)} ({len(валидация)/len(метаданни)*100:.1f}%)")
print(f"Записи за тест: {len(тест)} ({len(тест)/len(метаданни)*100:.1f}%)")
```

## 2. Практически съвети за подготовка на данни

### 2.1. Съвети за качество на аудиото

-   **Последователност е ключова:** Поддържайте последователно качество на записа, нива на силата на звука и фонов шум.
-   **Избягвайте ехо и реверберация:** Записвайте в акустично третирани помещения, когато е възможно.
-   **Използвайте качествен микрофон:** Инвестирайте в добър микрофон за по-чисти записи.
-   **Мониторинг на клипиране:** Избягвайте претоварване на аудиото, което води до изкривяване.

### 2.2. Съвети за транскрипции

-   **Последователност в стила:** Решете как ще обработвате числа, съкращения, акроними и придържайте се към това.
-   **Фонетична точност:** Уверете се, че транскрипциите отразяват точно произнесените думи, не предполагаемото намерение.
-   **Обработка на шумове:** Решете дали да включвате или изключвате нелингвистични звуци (кашляне, смях, въздишки).

### 2.3. Съвети за ефективност

-   **Автоматизирайте процеса:** Създайте скриптове за автоматизиране на повтарящи се задачи.
-   **Паралелна обработка:** Използвайте многонишкова обработка за по-бързо преобразуване на големи набори от данни.
-   **Инкрементална проверка:** Проверявайте качеството на малки партиди, докато напредвате, вместо да оставяте всичко за края.

### 2.4. Скриптове за проверка на аудио

Ето няколко полезни скрипта за проверка на качеството на вашите аудио данни:

```python
# Скрипт за проверка на свойствата на аудио файловете
import os
import librosa
import pandas as pd
from tqdm import tqdm

директория_с_аудио = "wavs/"
файлове = [f for f in os.listdir(директория_с_аудио) if f.endswith('.wav')]

резултати = []

for файл in tqdm(файлове, desc="Проверка на аудио файлове"):
    пълен_път = os.path.join(директория_с_аудио, файл)
    try:
        # Зареждане на аудио файла
        y, sr = librosa.load(пълен_път, sr=None)
        
        # Изчисляване на продължителността
        продължителност = librosa.get_duration(y=y, sr=sr)
        
        # Проверка на броя канали (моно/стерео)
        if y.ndim > 1:
            канали = y.shape[0]
        else:
            канали = 1
            
        # Изчисляване на RMS енергия (за нивото на силата на звука)
        rms = librosa.feature.rms(y=y).mean()
        
        резултати.append({
            'файл': файл,
            'честота_на_семплиране': sr,
            'продължителност': продължителност,
            'канали': канали,
            'rms_енергия': rms
        })
    except Exception as e:
        print(f"Грешка при обработка на {файл}: {str(e)}")

# Конвертиране на резултатите в DataFrame
df = pd.DataFrame(резултати)

# Показване на статистика
print("\nСтатистика за аудио файловете:")
print(f"Общ брой файлове: {len(df)}")
print(f"Уникални честоти на семплиране: {df['честота_на_семплиране'].unique()}")
print(f"Средна продължителност: {df['продължителност'].mean():.2f}s")
print(f"Мин. продължителност: {df['продължителност'].min():.2f}s")
print(f"Макс. продължителност: {df['продължителност'].max():.2f}s")
print(f"Файлове с повече от 1 канал: {(df['канали'] > 1).sum()}")

# Идентифициране на потенциални проблеми
проблемни_файлове = df[
    (df['продължителност'] < 0.5) |  # Прекалено кратки файлове
    (df['продължителност'] > 15) |   # Прекалено дълги файлове
    (df['канали'] > 1) |             # Не-моно файлове
    (df['честота_на_семплиране'] != df['честота_на_семплиране'].mode()[0]) |  # Различна честота на семплиране
    (df['rms_енергия'] < 0.01)       # Прекалено тихи файлове
]

if not проблемни_файлове.empty:
    print(f"\nНамерени {len(проблемни_файлове)} потенциално проблемни файлове:")
    print(проблемни_файлове)
    
    # Запазване на списъка с проблемни файлове
    проблемни_файлове.to_csv("проблемни_аудио_файлове.csv", index=False)
```

---

С правилно подготвен набор от данни, вие сте готови да преминете към настройката на средата за обучение и конфигурирането на вашия TTS модел.

**Следваща стъпка:** [Настройка за обучение](./2_TRAINING_SETUP.md){: .btn .btn-primary} | 
[Обратно към началото](#top){: .btn .btn-primary}