# Ръководство 3: Обучение на TTS модел

**Навигация:** [Главно README]({{ site.baseurl }}/languages/bg/){: .btn .btn-primary} | [Предишна стъпка: Настройка за обучение](./2_TRAINING_SETUP.md){: .btn .btn-primary} | [Следваща стъпка: Извеждане](./4_INFERENCE.md){: .btn .btn-primary} | 

Това ръководство обхваща процеса на обучение на вашия TTS модел, от стартиране на обучението до мониторинг и оптимизация.

---

## 1. Стартиране на обучението

### 1.1. Команди за обучение за различни рамки

Ето как да стартирате обучението с различни популярни TTS рамки:

#### Coqui TTS
```bash
# Обучение с Coqui TTS
tts --train --config_path config.json
```

#### ESPnet
```bash
# Обучение с ESPnet
cd egs2/your_dataset/tts1
./run.sh --stage 1 --stop-stage 6
```

#### VITS
```bash
# Обучение с VITS
python train.py -c configs/config.json -m your_model_name
```

### 1.2. Използване на GPU

Уверете се, че вашето обучение използва наличните GPU:

```bash
# Проверка на наличните GPU
nvidia-smi

# Задаване на конкретен GPU (ако имате няколко)
export CUDA_VISIBLE_DEVICES=0,1  # Използване на първите два GPU
```

За разпределено обучение на няколко GPU:

```bash
# Пример за разпределено обучение с Coqui TTS
CUDA_VISIBLE_DEVICES=0,1 python -m TTS.bin.distribute --script train_tts.py --config_path config.json
```

### 1.3. Възобновяване на обучението от контролна точка

Ако обучението е прекъснато, можете да го възобновите от последната контролна точка:

```bash
# Coqui TTS пример
tts --continue_path path/to/checkpoint --config_path config.json

# VITS пример
python train.py -c configs/config.json -m your_model_name --restore_from path/to/checkpoint
```

## 2. Мониторинг на обучението

### 2.1. Използване на TensorBoard

TensorBoard е мощен инструмент за визуализиране на прогреса на обучението:

```bash
# Стартиране на TensorBoard
tensorboard --logdir=path/to/logs
```

Ключови метрики за наблюдение:
-   **Загуба при обучение:** Трябва да намалява постепенно.
-   **Загуба при валидация:** Трябва да следва загубата при обучение без значително разминаване.
-   **Спектрограми:** Визуално сравнение между предсказаните и целевите спектрограми.
-   **Внимание (Attention):** За модели базирани на внимание, проверете дали вниманието е диагонално и последователно.

### 2.2. Слушане на примери за валидация

Периодично генерирайте и слушайте примери от валидационния набор:

```bash
# Coqui TTS пример за синтезиране на реч от контролна точка
tts --text "Това е тестово изречение." --model_path path/to/checkpoint --config_path config.json --out_path test_sample.wav
```

Обърнете внимание на:
-   **Качество на гласа:** Ясен, естествен, без изкривявания.
-   **Произношение:** Правилно произношение на думите.
-   **Прозодия:** Естествена интонация и ритъм.
-   **Стабилност:** Без пропуснати или повторени думи.

### 2.3. Проверка на контролните точки

Контролните точки се запазват периодично по време на обучението. Проверете директорията с контролни точки, за да видите прогреса:

```bash
# Изброяване на контролните точки
ls -la path/to/checkpoints/
```

Повечето рамки запазват "най-добрата" контролна точка въз основа на загубата при валидация.

## 3. Оптимизация на обучението

### 3.1. Настройка на хиперпараметрите

Ако обучението не напредва добре, обмислете настройка на тези хиперпараметри:

-   **Скорост на обучение:** Намалете, ако обучението е нестабилно; увеличете, ако е твърде бавно.
    ```bash
    # Пример за промяна на скоростта на обучение в конфигурационния файл
    sed -i 's/"lr": 0.001/"lr": 0.0005/' config.json
    ```
-   **Размер на партидата:** Намалете, ако срещате грешки за недостатъчна памет; увеличете за по-стабилно обучение.
    ```bash
    # Пример за промяна на размера на партидата
    sed -i 's/"batch_size": 32/"batch_size": 16/' config.json
    ```
-   **Градиентно клипиране:** Помага за стабилизиране на обучението, особено за рекурентни модели.
    ```json
    "grad_clip": 1.0,  # Добавете това към конфигурацията
    ```

### 3.2. Справяне с проблеми при обучението

#### Недостатъчна памет (OOM) грешки
```bash
# Опции за намаляване на използването на памет
# 1. Намалете размера на партидата
sed -i 's/"batch_size": 32/"batch_size": 16/' config.json

# 2. Активирайте смесена прецизност
sed -i 's/"mixed_precision": false/"mixed_precision": true/' config.json

# 3. Активирайте градиентно контролиране (ако се поддържа)
sed -i 's/"grad_checkpoint": false/"grad_checkpoint": true/' config.json
```

#### Нестабилно обучение
```bash
# Опции за стабилизиране на обучението
# 1. Намалете скоростта на обучение
sed -i 's/"lr": 0.001/"lr": 0.0003/' config.json

# 2. Увеличете градиентното клипиране
sed -i 's/"grad_clip": 5/"grad_clip": 1/' config.json

# 3. Променете оптимизатора
sed -i 's/"optimizer": "Adam"/"optimizer": "RAdam"/' config.json
```

#### Лошо качество на аудиото
```bash
# Проверка на аудио параметрите
# Уверете се, че параметрите на спектрограмата съответстват на вашите данни
grep -r "sample_rate\|n_fft\|hop_length" config.json

# Проверка на нормализацията на аудиото
python -c "import librosa; import numpy as np; y, sr = librosa.load('dataset/wavs/sample.wav'); print(f'Min: {y.min()}, Max: {y.max()}, Mean: {y.mean()}, Std: {y.std()}')"
```

## 4. Обучение от нулата срещу фина настройка

### 4.1. Обучение от нулата

Обучението от нулата е подходящо, когато:
- Имате голям набор от данни (10+ часа)
- Работите с език или глас, който значително се различава от наличните предварително обучени модели
- Имате специфични изисквания, които не могат да бъдат удовлетворени чрез фина настройка

**Предимства:**
- Пълен контрол върху архитектурата и обучението
- Потенциално по-добро качество за специфични случаи
- Не зависи от предразсъдъците на предварително обучените модели

**Недостатъци:**
- Изисква значително повече данни
- Отнема много повече време за обучение
- Изисква повече изчислителни ресурси
- По-трудно за оптимизиране

### 4.2. Фина настройка

Фината настройка е подходяща, когато:
- Имате ограничени данни (10 минути до няколко часа)
- Искате да адаптирате съществуващ модел към нов глас
- Имате ограничени изчислителни ресурси
- Нуждаете се от по-бързо време за обучение

**Предимства:**
- Изисква значително по-малко данни
- Много по-бързо обучение (часове вместо дни)
- Обикновено по-стабилно и по-лесно за оптимизиране
- Може да постигне отлично качество дори с ограничени данни

**Недостатъци:**
- Ограничен контрол върху някои аспекти на модела
- Може да наследи предразсъдъци или ограничения от базовия модел
- Не винаги е подходящо за езици с малко ресурси

### 4.3. Практически подход за избор

1. **Започнете с фина настройка**, ако е възможно, дори ако планирате обучение от нулата по-късно. Това ви дава бърз базов модел за сравнение.
2. **Оценете резултатите** от фината настройка. Ако качеството е задоволително, може да спрете тук.
3. **Преминете към обучение от нулата** само ако фината настройка не дава задоволителни резултати и имате достатъчно данни и ресурси.

## 5. Обучение на вокодер

Ако използвате двустепенен подход (акустичен модел + вокодер), може да се наложи да обучите персонализиран вокодер:

### 5.1. Подготовка на данни за вокодера

Вокодерите обикновено се обучават на същите аудио данни като акустичния модел:

```bash
# Пример за извличане на мел спектрограми за обучение на вокодер
python extract_mel_spectrograms.py --input_dir dataset/wavs/ --output_dir dataset/mels/
```

### 5.2. Обучение на HiFi-GAN вокодер

```bash
# Клониране на HiFi-GAN репозиторито
git clone https://github.com/jik876/hifi-gan.git
cd hifi-gan

# Обучение на HiFi-GAN
python train.py --input_mels_dir dataset/mels/ --input_wavs_dir dataset/wavs/ --config config_v1.json
```

### 5.3. Фина настройка на предварително обучен вокодер

Често е по-ефективно да настроите фино предварително обучен вокодер:

```bash
# Фина настройка на предварително обучен HiFi-GAN
python train.py --input_mels_dir dataset/mels/ --input_wavs_dir dataset/wavs/ --config config_v1.json --checkpoint_path pretrained/g_02500000
```

## 6. Съвети за успешно обучение

### 6.1. Общи съвети

-   **Започнете малко:** Първо тествайте с малък подмножество от данни, за да се уверите, че всичко работи.
-   **Постепенно увеличаване:** След като малкият тест работи, увеличете размера на данните и сложността на модела.
-   **Редовно валидиране:** Генерирайте и слушайте примери редовно, не разчитайте само на загубата.
-   **Запазвайте контролни точки:** Запазвайте контролни точки често и не изтривайте старите, докато не сте сигурни, че новите са по-добри.

### 6.2. Стратегии за фина настройка

-   **Замразяване на слоеве:** Някои рамки позволяват замразяване на части от мрежата (напр. текстовия енкодер или предиктора за продължителност) първоначално и обучение само на специфични компоненти (като вграждания на говорителя или декодера). Това понякога може да помогне за запазване на силните страни на базовия модел, докато адаптирате специфични аспекти. Проверете документацията на вашата рамка за `--freeze_layers` или подобни опции.
-   **Игнориране на слоеве:** Когато зареждате предварително обучения модел, може да искате да `ignore_layers` (или `reinitialize_layers`) като последния изходен слой или слоя за вграждане на говорителя, особено ако вашият набор от данни има различен брой говорители от предварително обучения модел.

### 6.3. Мониторинг на фината настройка

-   **Бързо първоначално подобрение:** Трябва да видите относително бързо намаляване на загубата при валидация в началото, докато моделът се адаптира към целевия глас.
-   **Фокус върху качеството на аудиото:** Обърнете специално внимание на синтезираните валидационни примери. Променя ли се идентичността на гласа към вашия целеви говорител? Ясна и стабилна ли е речта? Фината настройка често е повече за перцептивно качество, отколкото за достигане на абсолютната минимална стойност на загубата.

---

## 7. Изчерпателно ръководство за отстраняване на проблеми

Обучението на TTS модели може да бъде предизвикателно, с много потенциални проблеми. Този раздел предоставя решения за често срещани проблеми, които може да срещнете.

### 7.1. Често срещани съобщения за грешки и решения

| Съобщение за грешка | Възможни причини | Решения |
|:--------------|:----------------|:----------|
| `CUDA out of memory` | • Размерът на партидата е твърде голям<br>• Моделът е твърде голям за GPU<br>• Изтичане на памет | • Намалете размера на партидата<br>• Активирайте градиентно контролиране<br>• Използвайте смесена прецизност на обучение<br>• Намалете дължината на последователността |
| `RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long` | • Неправилен тип данни в набора от данни<br>• Несъвместими типове тензори | • Проверете предварителната обработка на данните<br>• Уверете се, че всички тензори имат правилния dtype<br>• Добавете изрично преобразуване на типа |
| `ValueError: too many values to unpack` | • Несъответствие между изходите на модела и очакванията на функцията за загуба<br>• Неправилен формат на данните | • Проверете структурата на изхода на модела<br>• Проверете имплементацията на функцията за загуба<br>• Дебъгвайте изходите на зареждащия данни |
| `FileNotFoundError: [Errno 2] No such file or directory` | • Неправилни пътища в конфигурацията<br>• Липсващи файлове с данни | • Проверете всички пътища на файлове<br>• Проверете целостта на файла с манифест<br>• Уверете се, че данните са изтеглени/извлечени |
| `KeyError: 'speaker_id'` | • Липсваща информация за говорителя<br>• Неправилен формат на набора от данни | • Проверете формата на набора от данни<br>• Проверете файла за съпоставяне на говорителите<br>• Добавете информация за говорителя към манифеста |
| `Loss is NaN` | • Скоростта на обучение е твърде висока<br>• Нестабилна инициализация<br>• Експлозия на градиента | • Намалете скоростта на обучение<br>• Добавете клипиране на градиента<br>• Проверете за деление на нула<br>• Нормализирайте входните данни |
| `ModuleNotFoundError: No module named 'X'` | • Липсваща зависимост<br>• Проблем с околната среда | • Инсталирайте липсващия пакет<br>• Проверете виртуалната среда<br>• Проверете версиите на пакетите |
| `RuntimeError: expected scalar type Float but found Double` | • Несъвместими типове тензори | • Добавете `.float()` към тензорите<br>• Проверете предварителната обработка на данните<br>• Стандартизирайте dtype в целия модел |

### 7.2. Проблеми с качеството на обучението

| Симптом | Възможни причини | Решения |
|:--------|:----------------|:----------|
| **Роботизирано/Бръмчащо аудио** | • Проблеми с вокодера<br>• Недостатъчно обучение<br>• Лоша предварителна обработка на аудиото | • Обучавайте вокодера по-дълго<br>• Проверете нормализацията на аудиото<br>• Проверете съответствието на честотата на семплиране |
| **Пропускане/Повторение на думи** | • Проблеми с вниманието<br>• Нестабилно обучение<br>• Недостатъчни данни | • Използвайте загуба на насочено внимание<br>• Добавете повече разнообразие на данните<br>• Намалете скоростта на обучение<br>• Проверете за дълги тишини в данните |
| **Неправилно произношение** | • Проблеми с нормализацията на текста<br>• Грешки във фонемите<br>• Несъответствие на езика | • Подобрете предварителната обработка на текста<br>• Използвайте вход базиран на фонеми<br>• Добавете речник за произношение |
| **Загуба на идентичност на говорителя** | • Свръхобучение към доминиращ говорител<br>• Слаби вграждания на говорителя<br>• Недостатъчни данни за говорителя | • Балансирайте данните за говорителя<br>• Увеличете размерността на вграждането на говорителя<br>• Използвайте адверсариална загуба на говорителя |
| **Бавно сходимост** | • Проблеми със скоростта на обучение<br>• Лоша инициализация<br>• Сложен набор от данни | • Опитайте различни графици на скоростта на обучение<br>• Използвайте трансферно обучение<br>• Първоначално опростете набора от данни |
| **Нестабилно обучение** | • Вариация на партидата<br>• Изключения в набора от данни<br>• Проблеми с оптимизатора | • Използвайте натрупване на градиента<br>• Почистете извънредните примери<br>• Опитайте различни оптимизатори |

### 7.3. Проблеми, специфични за рамката

#### Coqui TTS
```
# Грешка: "RuntimeError: Error in applying gradient to param_name"
# Решение: Проверете за NaN стойности във вашия набор от данни или намалете скоростта на обучение
python -c "import torch; torch.autograd.set_detect_anomaly(True)"  # Изпълнете преди обучението за дебъгване

# Грешка: "ValueError: Tacotron training requires `r` > 1"
# Решение: Задайте правилно фактора на редукция в конфигурацията
# Пример за поправка в config.json:
"r": 2  # Опитайте стойности между 2-5
```

#### ESPnet
```
# Грешка: "TypeError: forward() missing 1 required positional argument: 'feats'"
# Решение: Проверете форматирането на данните и се уверете, че feats са предоставени
# Дебъгване на зареждането на данни:
python -c "from espnet2.train.dataset import ESPnetDataset; dataset = ESPnetDataset(...); print(dataset[0])"
```

#### VITS/StyleTTS
```
# Грешка: "RuntimeError: expected scalar type Half but found Float"
# Решение: Осигурете последователна прецизност в целия модел
# Добавете към вашия скрипт за обучение:
model = model.half()  # Ако използвате смесена прецизност
# ИЛИ
model = model.float()  # Ако не използвате смесена прецизност
```

### 7.4. Проблеми с хардуера и средата

1. **Фрагментация на GPU паметта**
   - **Симптом**: OOM грешки след обучение в продължение на няколко часа въпреки достатъчната VRAM
   - **Решение**: Периодично рестартирайте обучението от контролна точка, използвайте по-малки партиди

2. **CPU тесни места**
   - **Симптом**: Използването на GPU флуктуира или остава ниско
   - **Решение**: Увеличете num_workers в DataLoader, използвайте по-бързо хранилище, предварително кеширайте наборите от данни

3. **Тесни места на дисковия I/O**
   - **Симптом**: Обучението спира периодично по време на зареждането на данни
   - **Решение**: Използвайте SSD хранилище, увеличете фактора на предварително извличане, кеширайте набора от данни в RAM

4. **Конфликти в средата**
   - **Симптом**: Мистериозни сривове или грешки при импортиране
   - **Решение**: Използвайте изолирани среди (conda/venv), проверете съвместимостта на CUDA/PyTorch

### 7.5. Стратегии за дебъгване

1. **Изолирайте проблема**
   ```bash
   # Тествайте зареждането на данни отделно
   python -c "from your_framework import DataLoader; loader = DataLoader(...); next(iter(loader))"
   
   # Тествайте прав проход с фиктивни данни
   python -c "import torch; from your_model import Model; model = Model(); x = torch.randn(1, 100); model(x)"
   ```

2. **Опростете, за да идентифицирате проблемите**
   - Обучавайте на малко подмножество (10-20 примера)
   - Временно деактивирайте увеличаването на данните
   - Първо опитайте с един говорител

3. **Визуализирайте междинните изходи**
   - Начертайте подравняванията на вниманието
   - Визуализирайте мел спектрограмите на различни етапи
   - Наблюдавайте нормите на градиента

4. **Активирайте подробно логване**
   ```bash
   # Добавете към вашия скрипт за обучение
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

5. **Използвайте TensorBoard профилиране**
   ```python
   # Добавете към вашия код за обучение
   from torch.profiler import profile, record_function
   with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:
       with record_function("model_inference"):
           # Вашият прав проход
   print(prof.key_averages().table())
   ```

---

След стартиране и наблюдение на обучението, следващата стъпка, след избиране на добра контролна точка, е да използвате модела за генериране на реч от нов текст.

**Следваща стъпка:** [Извеждане](./4_INFERENCE.md){: .btn .btn-primary} | 
[Обратно към началото](#top){: .btn .btn-primary}